imp <- lapply(c(readingSkills), function(y) {#
   lapply(seq(1, 3), function(b) {#
    varimp(cforest(score ~ ., data = readingSkills, control = cforest_unbiased(mtry = 2, ntree = 50)))#
  })#
})
imp
?install.packages
library(RWeka)
summary(iris)#
#
##   Sepal.Length   Sepal.Width    Petal.Length   Petal.Width #
##  Min.   :4.30   Min.   :2.00   Min.   :1.00   Min.   :0.1  #
##  1st Qu.:5.10   1st Qu.:2.80   1st Qu.:1.60   1st Qu.:0.3  #
##  Median :5.80   Median :3.00   Median :4.35   Median :1.3  #
##  Mean   :5.84   Mean   :3.06   Mean   :3.76   Mean   :1.2  #
##  3rd Qu.:6.40   3rd Qu.:3.30   3rd Qu.:5.10   3rd Qu.:1.8  #
##  Max.   :7.90   Max.   :4.40   Max.   :6.90   Max.   :2.5  #
##        Species  #
##  setosa    :50  #
##  versicolor:50  #
##  virginica :50  #
##                 #
##                 #
## #
#
library(RWeka)
iris_j48 <- J48(Species ~ ., data = iris)
iris_j48
?mobForestAnalysis
library(mobForest)
?mobForestAnalysis
data("BostonHousing", package = "mlbench")#
BostonHousing <- BostonHousing[1:90,c("rad", "tax", "crim", "medv", "lstat")]#
#
## Recursive partitioning based on linear regression model medv ~ lstat with 3 trees. #
## 1 core/processor used. Supply more processors using 'processors' argument#
rfout <- mobForestAnalysis(as.formula(medv ~ lstat), #
c("rad", "tax", "crim"), mobForest.controls = #
mobForest_control(ntree = 3, mtry = 2, replace = TRUE, #
alpha = 0.05, bonferroni = TRUE, minsplit = 25), #
data = BostonHousing, processors = 1, model = linearModel)
nrow(BostonHousing)
install.packages('nutshell')
library(zoo)
x.Date <- as.Date(paste(2004, rep(1:4, 4:1), sample(1:28, 10), sep = "-"))#
x <- zoo(rnorm(12), x.Date)
x
fix(x)
is.matrix(x)
class(x)
rollmean(x,3)
xm <- zoo(matrix(1:12, 4, 3), x.Date[1:4])
xm
rollmean(xm,3)
mat = matrix(ncol=2, byrow=TRUE,)
c(1,2,)
mat = matrix(ncol=2, byrow=TRUE,
c(1,2,)
)
mat = matrix(ncol=2, byrow=TRUE,
c(1,2,
2,5,
6,3,
1,1))
mat
mat/rbind(NA, mat[-nrow(mat),]) - 1
mat/rbind(NA, mat[-nrow(mat),])
mat[-1,]/mat[-nrow(mat),] - 1
X = rnorm(100)#
Y= rnorm(100)#
#
plot(Y~X)#
lines(lowess(Y~X), f=.8)#
lines(lowess(Y~X), f=.1)
?lowess
plot(Y~X)#
lines(lowess(Y~X, f=.8))#
lines(lowess(Y~X, f=.1))
obj1 = 5#
obj2 <- 5#
#
# just type name of object to print value#
obj1#
obj2
obj3 = obj1+obj2
obj3
obj3 = "ABC"
obj3
?read.table
install.package("sna")
install.packages("sna")
library(sna)
data(Galton)
data(galton)
library(MASS)
data()
data(iris)
fix(iris)
data(iris)
is.data.frame(iris)
fix(iris)
head(iris)
iris$Sepal.Length
iris.mat = as.matrix(iris)
iris.mat
iris.mat$Sepal.Length
iris.frame = as.data.frame(iris.mat)
plot(Sepal.Length)
plot(iris$Sepal.Length)
mod.1 = lm(iris$Sepal.Length ~ iris$Petal.Width + iris$Petal.Length)
mod.2 = lm(Sepal.Length ~ Petal.Width + Petal.Length, data=iris)
summary(mod.1)
mod.1$coef
mod.1$resid
advice_data_frame <- read.table('http://sna.stanford.edu/sna_R_labs/data/Krack-High-Tec-edgelist-Advice.txt')
fix(advice_data_frame)
df = cbind(iris$Sepal.Length, iris$Species)
is.data.frame(df)
is.matrix(df)
source("http://sna.stanford.edu/setup.R")
library(igraph)
advice_data_frame <- read.table('http://sna.stanford.edu/sna_R_labs/data/Krack-High-Tec-edgelist-Advice.txt')#
friendship_data_frame <- read.table('http://sna.stanford.edu/sna_R_labs/data/Krack-High-Tec-edgelist-Friendship.txt')#
reports_to_data_frame <- read.table('http://sna.stanford.edu/sna_R_labs/data/Krack-High-Tec-edgelist-ReportsTo.txt')
advice_data_frame
head(friendship_data_frame)
attributes <- read.csv('http://sna.stanford.edu/sna_R_labs/data/Krack-High-Tec-Attributes.csv', header=T)
attributes
colnames(advice_data_frame) <- c('ego', 'alter', 'advice_tie')#
head(advice_data_frame)#
colnames(friendship_data_frame) <- c('ego', 'alter', 'friendship_tie')#
head(friendship_data_frame)#
colnames(reports_to_data_frame) <- c('ego', 'alter', 'reports_to_tie')#
head(reports_to_data_frame)
advice_data_frame$ego == friendship_data_frame$ego
which(advice_data_frame$ego != friendship_data_frame$ego)
which(advice_data_frame$alter != friendship_data_frame$alter)#
which(reports_to_data_frame$alter != friendship_data_frame$alter)#
which(reports_to_data_frame$ego != friendship_data_frame$ego)
krack_full_data_frame <- cbind(advice_data_frame, #
	friendship_data_frame$friendship_tie, #
	reports_to_data_frame$reports_to_tie)#
head(krack_full_data_frame)
names(krack_full_data_frame)[4:5] <- c("friendship_tie",
"reports_to_tie")
head(krack_full_data_frame)
krack_full_data_frame <- data.frame(ego = advice_data_frame[,1],#
	alter = advice_data_frame[,2],#
	advice_tie = advice_data_frame[,3],#
	friendship_tie = friendship_data_frame[,3], #
	reports_to_tie = reports_to_data_frame[,3])#
head(krack_full_data_frame)
krack_full_nonzero_edges <- subset(krack_full_data_frame, #
	(advice_tie > 0 | friendship_tie > 0 | reports_to_tie > 0))#
head(krack_full_nonzero_edges)
krack_full <- graph.data.frame(krack_full_nonzero_edges)
summary(krack_full)
get.edge.attribute(krack_full, 'advice_tie')
get.edge.attribute(krack_full, 'friendship_tie')
get.edge.attribute(krack_full, 'reports_to_tie')
krack_full_symmetrized <- as.undirected(krack_full, mode='collapse')#
summary(krack_full_symmetrized)
for (i in V(krack_full)) {#
    for (j in names(attributes)) {#
        krack_full <- set.vertex.attribute(krack_full, #
                                           j, #
                                           index = i, #
                                           attributes[i + 1, j])#
    }#
}
attributes = cbind(1:length(attributes[,1]), attributes)#
krack_full <- graph.data.frame(d = krack_full_nonzero_edges, #
                               vertices = attributes)
summary(krack_full)#
# We can see a list of the values for a given attribute for all of#
# the actors in the network.#
get.vertex.attribute(krack_full, 'AGE')#
get.vertex.attribute(krack_full, 'TENURE')#
get.vertex.attribute(krack_full, 'LEVEL')#
get.vertex.attribute(krack_full, 'DEPT')
plot(krack_full)
krack_advice_only <- delete.edges(krack_full, #
    E(krack_full)[get.edge.attribute(krack_full,#
    name = "advice_tie") == 0])#
summary(krack_advice_only)
plot(krack_advice_only)
krack_friendship_only <- delete.edges(krack_full, #
    E(krack_full)[get.edge.attribute(krack_full, #
    name = "friendship_tie") == 0])
plot(krack_friendship_only)
krack_reports_to_only <- delete.edges(krack_full, #
    E(krack_full)[get.edge.attribute(krack_full, #
    name = "reports_to_tie") == 0])
plot(krack_reports_to_only)
reports_to_layout <- layout.fruchterman.reingold(krack_reports_to_only)
plot(krack_reports_to_only,
layout=reports_to_layout)
dept_vertex_colors = get.vertex.attribute(krack_full,"DEPT")#
colors = c('Black', 'Red', 'Blue', 'Yellow', 'Green')#
dept_vertex_colors[dept_vertex_colors == 0] = colors[1]#
dept_vertex_colors[dept_vertex_colors == 1] = colors[2]#
dept_vertex_colors[dept_vertex_colors == 2] = colors[3]#
dept_vertex_colors[dept_vertex_colors == 3] = colors[4] #
dept_vertex_colors[dept_vertex_colors == 4] = colors[5]
plot(krack_reports_to_only, #
    layout=reports_to_layout, #
    vertex.color=dept_vertex_colors, #
    vertex.label=NA, #
    edge.arrow.size=.5)
tenure_vertex_sizes = get.vertex.attribute(krack_full,"TENURE")
plot(krack_reports_to_only, #
     layout=reports_to_layout, #
     vertex.color=dept_vertex_colors, #
     vertex.label=NA, #
     edge.arrow.size=.5,#
     vertex.size=tenure_vertex_sizes)
tie_type_colors = c(rgb(1,0,0,.5), rgb(0,0,1,.5), rgb(0,0,0,.5))#
E(krack_full)$color[ E(krack_full)$advice_tie==1 ] = tie_type_colors[1]#
E(krack_full)$color[ E(krack_full)$friendship_tie==1 ] = tie_type_colors[2]#
E(krack_full)$color[ E(krack_full)$reports_to_tie==1 ] = tie_type_colors[3]#
E(krack_full)$arrow.size=.5 #
V(krack_full)$color = dept_vertex_colors#
V(krack_full)$frame = dept_vertex_colors
plot(krack_full, #
     layout=reports_to_layout, #
     vertex.color=dept_vertex_colors, #
     vertex.label=NA, #
     edge.arrow.size=.5,#
     vertex.size=tenure_vertex_sizes)
legend(1, #
       1.25,#
       legend = c('Advice', #
                  'Friendship',#
                  'Reports To'), #
       col = tie_type_colors, #
       lty=1,#
       cex = .7)
plot(krack_friendship_only, #
     layout=reports_to_layout, #
     vertex.color=dept_vertex_colors, #
     vertex.label=NA, #
     edge.arrow.size=.5,#
     vertex.size=tenure_vertex_sizes, #
     main='Krackhardt High-Tech Managers')
library(ergm)
data(studentnets.ergm173, package = "NetData")
rm(list=ls())
load the "ergm" library#
library(ergm)#
## Load the data:#
data(studentnets.ergm173, package = "NetData")
id <- seq(1,22,1)
nodes<-cbind(id, nodes)
nodes
edges2<-merge(nodes[,1:2], edges, by.x = "std_id", by.y="alter_id")
names(edges2)[1]<-"alter_id"
names(edges2)[2]<-"alter_R_id"#
edges3<- merge(nodes[,1:2], edges2, by.x = "std_id", by.y="ego_id")#
# shows that we merged new alter id that reflects #
# integer id which R requires.#
names(edges3)[1]<-"ego_id"#
names(edges3)[2]<-"ego_R_id"#
edges3#
# The edges3 dataset now contains integer-increasing IDs sorted by#
# ego_R_id. For our work, we will use the ego_R_id and alter_R_id#
# values, but we retain the std_id values for reference.#
# Specify the network we'll call net - where dyads #
# are the unit of analysis...#
net<-network(edges3[,c("ego_R_id", "alter_R_id")])
set.edge.attribute(net, "ego_R_id", edges[,2])#
set.edge.attribute(net, "alter_R_id", edges[,4])
net %v% "gender" <- nodes[,3]#
net %v% "grade" <- nodes[,4]#
net %v% "race" <- nodes[,5]#
net %v% "pci" <- nodes[,6]#
# Review some summary information regarding the network to make#
# sure we have #specified things correctly.  #
summary(net)
plot(net)
m1<-ergm(net ~ edges + mutual + nodematch("gender") + absdiff#
    ("pci"),burnin=15000,MCMCsamplesize=30000,verbose=FALSE)
mcmc.diagnostics(m1)
summary(m1)
lapply(m1[1],exp)
seat <- net
set.edge.attribute(seat, "seat_net", edges3[,7])
set.edge.attribute(net, "friend1", edges3[,5])
test<-edges["sem1_friend">=1,]
test2<-merge(nodes[,1:2], test, by.x = "std_id", by.y="alter_id")#
names(test2)[1]<-"alter_id"#
names(test2)[2]<-"alter_R_id"#
test3<- merge(nodes[,1:2], test2, by.x = "std_id", by.y="ego_id")#
names(test3)[1]<-"ego_id"#
names(test3)[2]<-"ego_R_id"#
net1<-network(test3[,c("ego_R_id", "alter_R_id")])#
A<-as.matrix(net1)#
B<-t(as.matrix(net1)) #B = A transpose#
mut_mat <- A + B#
lag_mut<-as.network(mut_mat) # relies on dichotomous#
                             # interpretation of edges
m2<-ergm(net ~ edges + mutual + nodematch("gender") + #
    nodematch("race")  + edgecov(lag_mut),burnin=20000,#
    MCMCsamplesize=70000,verbose=FALSE,seed=25,#
    calc.mcmc.se = FALSE,maxit=6)#
pdf("8.3_lab8_mcmc_m2.pdf")#
mcmc.diagnostics(m2)
dev.off()
summary(m2)
m2.sim<-simulate(m2,nsim=100);#
simnet1<-m2.sim$networks[[1]]#
summary(simnet1)
plot(m2.sim$networks[[1]],vertex.col="WHITE")
m2.gof <- gof(m2~idegree)
plot(m2.gof)
update.packages(checkBuilt=TRUE, ask=FALSE)
library(PerfMeas)
install.packages('edarf')
install.packages('devtools')
install_github('zmjones/edarf')
library(devtools)
install_github('zmjones/edarf')
data(swiss)
pd_rfsrc <- partial_dependence(fit_rfsrc, swiss, "Education")
library(edarf)
pd_rfsrc <- partial_dependence(fit_rfsrc, swiss, "Education")
library(randomForest)#
library(party)#
library(randomForestSRC)#
library(edarf)
pd_rfsrc <- partial_dependence(fit_rfsrc, swiss, "Education")
fit_rfsrc <- rfsrc(Species ~ ., iris)
pd_rfsrc <- partial_dependence(fit_rfsrc, iris, "Petal.Width")
pd_rfsrc
plot(pd_rfsrc)
5/6
.83*60
6*60+50
410/6
68.3*1769
/60
(68.3*1769)/60
((68.3*1769)/60)/60
install.packages('stpp')
library(stpp)
data('northcumri')
data('northcumbria')
fmd = as.3dpoints(fmd)
data('fmd')
fmd = as.3dpoints(fmd)
plot(fmd, s.region=northcumbria)
class(northcumbria)
dim(northcumbria)
northcumbria
class(fmd)
data('fmd')
class(fmd)
dim(fmd)
fmd[1,]
animation(fmd, runtime=10, cex = 0.5, s.region=northcumbria)
install.packages('ptproc')
install.packages("ptproc", #
repos="http://www.biostat.jhsph.edu/~rpeng/software", type="source")
library(randomForestSRC)
detectCores()
options(rf.cores=3)
?randomForestSRC
?rfsrc
library(rfsrc)
library(randomForestSRC)
?randomForestSRC
library(gbm)
pkgs = list('caret','tidyr')#
invisible(lapply(pkgs, library, character.only=TRUE, quietly=TRUE))#
setwd('~/kaggle/Bike Share/')#
#
train = read.csv('train.csv')#
test = read.csv('test.csv')#
#
fmla = formula(count ~ season + holiday + workingday + weather + temp + atemp + humidity + windspeed)
mod.gbm = train(fmla, #
							data = train,#
							method = 'gbm',#
							n.trees=50000)
warnings()
bootControl = trainControl(number = 200)#
gbm.grid = expand.grid(.interaction.depth = (1:5) * 2, + .n.trees = (1:10)*25, .shrinkage = .1)#
gbm.fit = train(fmla, data=train, method = "gbm", trControl = bootControl, verbose = FALSE, bag.fraction = 0.5, tuneGrid = gbm.grid)
bootControl = trainControl(number = 200)#
gbm.grid = expand.grid(.interaction.depth = (1:5) * 2, .n.trees = (1:10)*25, .shrinkage = .1)#
gbm.fit = train(fmla, data=train, method = "gbm", trControl = bootControl, verbose = FALSE, bag.fraction = 0.5, tuneGrid = gbm.grid)
gbm.mod = gbm(fmla, data = data, distribution = "poisson", n.trees=1000)
gbm.mod = gbm(fmla, data = train, distribution = "poisson", n.trees=1000)
gbm.mod = gbm(fmla, data = train, distribution = "poisson", n.trees=10000)
colnames(test)
test.x = test[c(2:9)]
pred.count = predict(gbm.mod, test.x)
?predict
pred.count = predict(gbm.mod, test.x, n.trees=10000, type="response")
head(pred.count)
submission = cbind(test$datetime, pred.count)
colnames(submission) = c('datetime','count')
write.csv(submission, 'predicted_counts.csv', row.names=FALSE)
head(test)
datetime = test$datetime
head(datetime)
submission = cbind(test$datetime, pred.count)
head(submission)
submission = cbind(datetime, pred.count)
head(submission)
is.data.frame(submission)
class(submission)
class(datetime)
submission = data.frame()
class(submission)
submission$datetime = test$datetime#
submission$count = pred.count
submission = data.frame(test$datetime)
class(submission)
head(submission)
submission$count = pred.count
head(submission)
colnames(submission) = c('datetime','count')
write.csv(submission, 'predicted_counts.csv', row.names=FALSE)
gbm.mod = gbm(fmla, data = train, distribution = "poisson", n.trees=100000)
train$weather = factor(train$weather)#
train$holiday = factor(train$holiday)#
train$workingday = factor(train$workingday)#
train$season = factor(train$season)#
#
test$weather = factor(test$weather)#
test$holiday = factor(test$holiday)#
test$workingday = factor(test$workingday)#
test$season = factor(test$season)
gbm.mod = gbm(fmla, data = train, distribution = "poisson", n.trees=100000)
test.x = test[c(2:9)]#
pred.count = predict(gbm.mod, test.x, n.trees=100000, type="response")#
submission = data.frame(test$datetime)#
submission$count = pred.count#
colnames(submission) = c('datetime','count')#
write.csv(submission, 'predicted_counts.csv', row.names=FALSE)
m(list=ls())#
#
pkgs = list('randomForest','party','randomForestSRC','foreign')#
invisible(lapply(pkgs, library, character.only=TRUE, quietly=TRUE))#
#
setwd('~/bensfisher.github.io/Replication/Random Forests in R/')
bkz = read.dta('BKZ.dta')#
bkz$disp = as.factor(bkz$disp)#
bkz$logpy = log(bkz$py +1)#
bkz$contig = as.factor(bkz$contig)#
fmla = formula(as.factor(disp) ~ aysm + contig + ally + sq + dema + demb + logpy)
ptm = proc.time()#
src.mod = rfsrc(fmla, bkz, ntree=500, mtry=3, importance='permute', var.used='all.trees')#
src.time = proc.time() - ptm
ptm = proc.time()#
src.mod = rfsrc(fmla, bkz, ntree=500, mtry=3, importance=c('permute', 'permute.ensemble'), var.used='all.trees')#
src.time = proc.time() - ptm
src.mod
im = vimp(src.mod)
src.mod = rfsrc(fmla, bkz, ntree=500, mtry=3, importance=c('permute.ensemble'), var.used='all.trees')
